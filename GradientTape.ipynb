{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientTape.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMomA/88L+ew11doj1yTHYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamSakamuri/deeplearning/blob/main/GradientTape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b_Kzj9Y1xYNN"
      },
      "outputs": [],
      "source": [
        "# TensorFlow and tf.keras\n",
        "# https://www.tensorflow.org/guide/autodiff\n",
        "\n",
        "# Computing gradients\n",
        "# To differentiate automatically, TensorFlow needs to remember what operations happen in what order during the forward pass.\n",
        "# Then, during the backward pass, TensorFlow traverses this list of operations in reverse order to compute gradients.\n",
        "\n",
        "# Gradient tapes\n",
        "# TensorFlow provides the tf.GradientTape API for automatic differentiation; that is, computing the gradient of a computation with respect to some inputs, usually tf.Variables. \n",
        "# TensorFlow \"records\" relevant operations executed inside the context of a tf.GradientTape onto a \"tape\". \n",
        "# TensorFlow then uses that tape to compute the gradients of a \"recorded\" computation using reverse mode differentiation.\n",
        "\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For automatic differentiation\n",
        "# Very useful when we want to have fine control over the differentiation\n",
        "\n",
        "# Refer: https://www.tensorflow.org/api_docs/python/tf/GradientTape\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
        "x = tf.Variable(3.0, trainable=True)\n",
        "with tf.GradientTape() as t:\n",
        "    t.watch(x)\n",
        "    y = x**2\n",
        "\n",
        "print(t.gradient(y, x).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39zb12xHxavj",
        "outputId": "063c4cfe-5633-40a8-dcf5-0d9e951eb66e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant(3.0)\n",
        "with tf.GradientTape() as g:\n",
        "  g.watch(x)\n",
        "  with tf.GradientTape() as gg:\n",
        "    gg.watch(x)\n",
        "    y = x * x\n",
        "  dy_dx = gg.gradient(y, x)     # Will compute to 6.0\n",
        "d2y_dx2 = g.gradient(dy_dx, x)  # Will compute to 2.0\n",
        "\n",
        "print(dy_dx)\n",
        "print(d2y_dx2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x392BxIx3KUo",
        "outputId": "84ffc809-f875-4877-a536-128ab09114c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "tf.Tensor(2.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.Variable(3.0, trainable=True)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "  # g.watch(x)\n",
        "  y = x * x\n",
        "  z = y * y\n",
        "dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
        "dy_dx = g.gradient(y, x)  # 6.0\n",
        "\n",
        "print(dz_dx,dy_dx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA-Iyd2e3SpF",
        "outputId": "77fab345-abb5-4c7b-d411-a7da8511205c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(108.0, shape=(), dtype=float32) tf.Tensor(6.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient w.r.t multiple variables\n",
        "\n",
        "x = tf.constant(3.0)\n",
        "y = tf.constant(4.0)\n",
        "with tf.GradientTape(persistent=True) as g:\n",
        "  g.watch(x)\n",
        "  g.watch(y)\n",
        "  z = y * y + x * x\n",
        "dz_dx_dy = g.gradient(z, [x,y])  \n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "print(dz_dx_dy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpUNmLdZ3YZv",
        "outputId": "813151ce-da11-4db3-c3a5-d888376a75b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3.0, shape=(), dtype=float32)\n",
            "tf.Tensor(4.0, shape=(), dtype=float32)\n",
            "[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ]
        }
      ]
    }
  ]
}